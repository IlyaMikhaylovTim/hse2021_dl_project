{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"EXPERIMENTS.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0648eaa0037d47e2878f597d3e245277":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","state":{"_view_name":"VBoxView","_dom_classes":[],"_model_name":"VBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9f687d7cd3f64a81a2a36bbed39e62b4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_dbb8abb881e8462b90325cc42f433977","IPY_MODEL_ee812dcb79464ee9b3e0679ee7a6186f"]}},"9f687d7cd3f64a81a2a36bbed39e62b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dbb8abb881e8462b90325cc42f433977":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","state":{"_view_name":"LabelView","style":"IPY_MODEL_0b7abf6dedd1443096a52063541ec970","_dom_classes":[],"description":"","_model_name":"LabelModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0.02MB of 0.02MB uploaded (0.00MB deduped)\r","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_babec96a708f4c4481e4778a23f9a2a4"}},"ee812dcb79464ee9b3e0679ee7a6186f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_337b841cca96421880949ba0d9fe9386","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dbca1875156f49328a32153b5863e37e"}},"0b7abf6dedd1443096a52063541ec970":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"babec96a708f4c4481e4778a23f9a2a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"337b841cca96421880949ba0d9fe9386":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"dbca1875156f49328a32153b5863e37e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"UNizmVRsRkdf"},"source":["### Imports"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s7U9xxsLYj_j","executionInfo":{"status":"ok","timestamp":1623402186494,"user_tz":-180,"elapsed":355,"user":{"displayName":"Дмитрий Галимзянов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZ2mpZj6x-74uzGNTk9Ws2YdRT3z-muP6KTkS4zg=s64","userId":"11134509458244039564"}},"outputId":"bca388ac-a8f0-4dfa-9a16-f0aed0696d21"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x7YKlndhYpf9","executionInfo":{"status":"ok","timestamp":1623402188300,"user_tz":-180,"elapsed":199,"user":{"displayName":"Дмитрий Галимзянов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZ2mpZj6x-74uzGNTk9Ws2YdRT3z-muP6KTkS4zg=s64","userId":"11134509458244039564"}},"outputId":"7e84503f-c8e3-484a-89da-fa60caaefdde"},"source":["!pwd"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sIqHj75iYoZ-","executionInfo":{"status":"ok","timestamp":1623402189766,"user_tz":-180,"elapsed":207,"user":{"displayName":"Дмитрий Галимзянов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZ2mpZj6x-74uzGNTk9Ws2YdRT3z-muP6KTkS4zg=s64","userId":"11134509458244039564"}}},"source":["PATH_TO_FOLDER = '/content/drive/MyDrive/DL_project/EXPERIMENTS'"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3OzD_NNGYqL_","executionInfo":{"status":"ok","timestamp":1623402191008,"user_tz":-180,"elapsed":212,"user":{"displayName":"Дмитрий Галимзянов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZ2mpZj6x-74uzGNTk9Ws2YdRT3z-muP6KTkS4zg=s64","userId":"11134509458244039564"}},"outputId":"91943063-a9bc-4a93-d431-443b4bcba3cb"},"source":["%cd {PATH_TO_FOLDER}"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/DL_project/EXPERIMENTS\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OnYyWY9gQMJq","executionInfo":{"status":"ok","timestamp":1623402194011,"user_tz":-180,"elapsed":197,"user":{"displayName":"Дмитрий Галимзянов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZ2mpZj6x-74uzGNTk9Ws2YdRT3z-muP6KTkS4zg=s64","userId":"11134509458244039564"}}},"source":["%load_ext autoreload\n","%autoreload 2"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"7B6BRDsAMTLc","executionInfo":{"status":"ok","timestamp":1623402195531,"user_tz":-180,"elapsed":686,"user":{"displayName":"Дмитрий Галимзянов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZ2mpZj6x-74uzGNTk9Ws2YdRT3z-muP6KTkS4zg=s64","userId":"11134509458244039564"}}},"source":["from models import MLP, NAC, NALU"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q4cW8u3dVAah","executionInfo":{"status":"ok","timestamp":1623402196863,"user_tz":-180,"elapsed":201,"user":{"displayName":"Дмитрий Галимзянов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZ2mpZj6x-74uzGNTk9Ws2YdRT3z-muP6KTkS4zg=s64","userId":"11134509458244039564"}}},"source":["import math\n","import random\n","import numpy as np\n","from tqdm.notebook import tqdm\n","from copy import deepcopy\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# Ensure deterministic behavior\n","torch.backends.cudnn.deterministic = True\n","random.seed(hash(\"setting random seeds\") % 2**32 - 1)\n","np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n","torch.manual_seed(hash(\"by removing stochasticity\") % 2**32 - 1)\n","torch.cuda.manual_seed_all(hash(\"so runs are repeatable\") % 2**32 - 1)\n","\n","# Device configuration\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"EfZo_iDS64cU"},"source":["%%capture\n","!pip install wandb --upgrade"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fXey7HaB0hLQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623402201402,"user_tz":-180,"elapsed":1804,"user":{"displayName":"Дмитрий Галимзянов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZ2mpZj6x-74uzGNTk9Ws2YdRT3z-muP6KTkS4zg=s64","userId":"11134509458244039564"}},"outputId":"4ece5862-b661-437f-f011-62bc5cb5fea2"},"source":["import wandb\n","wandb.login()"],"execution_count":8,"outputs":[{"output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgalmitr\u001b[0m (use `wandb login --relogin` to force relogin)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"ku_2dN30SP_k"},"source":["### INTERPOLATION Parameters"]},{"cell_type":"code","metadata":{"id":"VR9tjOmKNCnO","executionInfo":{"status":"ok","timestamp":1623402336774,"user_tz":-180,"elapsed":209,"user":{"displayName":"Дмитрий Галимзянов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZ2mpZj6x-74uzGNTk9Ws2YdRT3z-muP6KTkS4zg=s64","userId":"11134509458244039564"}}},"source":["NAMES = dict(\n","    project = 'INTERPOLATION',\n","    tags = 'preparation'\n",")\n","\n","MODEL_PARAMETERS = dict(\n","    in_dim=2,\n","    out_dim=1,\n","    NUM_LAYERS = 2,\n","    HIDDEN_DIM = 2,\n",")\n","\n","ARITHMETIC_PARAMETERS = dict(\n","    num_train=500, \n","    num_test=50,\n","    dim=100, \n","    num_sum=5,\n","    RANGE = [5, 10]\n",")\n","\n","TRAIN_PARAMETERS = dict(\n","                        LEARNING_RATE = 1e-2,\n","                        # NUM_ITERS = int(1e5),\n","                        NUM_ITERS = int(50000),\n","                        activation='relu6'\n","                        )\n","\n","ARITHMETIC_FUNCTIONS = {\n","    'add': lambda x, y: x + y,\n","    'sub': lambda x, y: x - y,\n","    'mul': lambda x, y: x * y,\n","    'div': lambda x, y: x / y,\n","    'squared': lambda x, y: torch.pow(x, 2),\n","    'root': lambda x, y: torch.sqrt(x)\n","    }\n","\n","MODELS = {\n","        'MLP': MLP, \n","        'NAC': NAC, \n","        'NALU': NALU\n","        }"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"N6hVeaS2Nay8"},"source":["# def get_id():\n","#     id_dct = {}\n","#     for i, key in enumerate(ARITHMETIC_FUNCTIONS.keys()):\n","#         id_dct[key] = i\n","#     return id_dct\n","\n","# FUNC_id = get_id()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QJJh4VJ3UgAo"},"source":["### Config for Wandb"]},{"cell_type":"code","metadata":{"id":"a-SoY2z7PtIZ","executionInfo":{"status":"ok","timestamp":1623402364412,"user_tz":-180,"elapsed":205,"user":{"displayName":"Дмитрий Галимзянов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZ2mpZj6x-74uzGNTk9Ws2YdRT3z-muP6KTkS4zg=s64","userId":"11134509458244039564"}}},"source":["def create_config(model, function):\n","    config = {'model': model,\n","              'function': function}\n","              \n","    models = MODEL_PARAMETERS.copy()\n","    funcs = ARITHMETIC_PARAMETERS.copy()\n","    params = TRAIN_PARAMETERS.copy()\n","    names = NAMES.copy()\n","\n","    for key, value in models.items():\n","        config[key] = value\n","    for key, value in funcs.items():\n","        config[key] = value\n","    for key, value in params.items():\n","        config[key] = value\n","    for key, value in names.items():\n","        config[key] = value\n","\n","    return config"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u8kAWaTFRw9l"},"source":["### Example of config"]},{"cell_type":"code","metadata":{"id":"NhrJi837r6Pr","executionInfo":{"status":"ok","timestamp":1623402366338,"user_tz":-180,"elapsed":339,"user":{"displayName":"Дмитрий Галимзянов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZ2mpZj6x-74uzGNTk9Ws2YdRT3z-muP6KTkS4zg=s64","userId":"11134509458244039564"}}},"source":["config = create_config('MLP', 'add')"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"5QV5eWvxsCrE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623402367219,"user_tz":-180,"elapsed":220,"user":{"displayName":"Дмитрий Галимзянов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZ2mpZj6x-74uzGNTk9Ws2YdRT3z-muP6KTkS4zg=s64","userId":"11134509458244039564"}},"outputId":"f1835745-8e27-4fb6-d51b-db5cc2d06f37"},"source":["config"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'HIDDEN_DIM': 2,\n"," 'LEARNING_RATE': 0.01,\n"," 'NUM_ITERS': 50000,\n"," 'NUM_LAYERS': 2,\n"," 'RANGE': [5, 10],\n"," 'activation': 'relu6',\n"," 'dim': 100,\n"," 'function': 'add',\n"," 'in_dim': 2,\n"," 'model': 'MLP',\n"," 'num_sum': 5,\n"," 'num_test': 50,\n"," 'num_train': 500,\n"," 'out_dim': 1,\n"," 'project': 'INTERPOLATION',\n"," 'tags': 'preparation'}"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"kSGKezIETDp3"},"source":["### Iteration on models and arithmetic functions"]},{"cell_type":"code","metadata":{"id":"2WdUOf70PtF5","colab":{"base_uri":"https://localhost:8080/","height":629,"referenced_widgets":["0648eaa0037d47e2878f597d3e245277","9f687d7cd3f64a81a2a36bbed39e62b4","dbb8abb881e8462b90325cc42f433977","ee812dcb79464ee9b3e0679ee7a6186f","0b7abf6dedd1443096a52063541ec970","babec96a708f4c4481e4778a23f9a2a4","337b841cca96421880949ba0d9fe9386","dbca1875156f49328a32153b5863e37e"]},"executionInfo":{"status":"error","timestamp":1623402385608,"user_tz":-180,"elapsed":10141,"user":{"displayName":"Дмитрий Галимзянов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZ2mpZj6x-74uzGNTk9Ws2YdRT3z-muP6KTkS4zg=s64","userId":"11134509458244039564"}},"outputId":"c4081038-4f4b-454c-dc07-669595b1c4d8"},"source":["mdls = MODELS.keys()\n","fncts = ARITHMETIC_FUNCTIONS.keys()\n","\n","for function in fncts:\n","    for arch in mdls:\n","        config = create_config(arch, function)\n","        # Build, train and analyze the model with the pipeline\n","        model = model_pipeline(config)"],"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","                Tracking run with wandb version 0.10.32<br/>\n","                Syncing run <strong style=\"color:#cdcd00\">add_MLP</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n","                Project page: <a href=\"https://wandb.ai/galmitr/INTERPOLATION\" target=\"_blank\">https://wandb.ai/galmitr/INTERPOLATION</a><br/>\n","                Run page: <a href=\"https://wandb.ai/galmitr/INTERPOLATION/runs/qxwbknjz\" target=\"_blank\">https://wandb.ai/galmitr/INTERPOLATION/runs/qxwbknjz</a><br/>\n","                Run data is saved locally in <code>/content/drive/My Drive/DL_project/EXPERIMENTS/wandb/run-20210611_090615-qxwbknjz</code><br/><br/>\n","            "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\t1/50000: loss: 5403.0131836 - mea: 73.4043427\n","\t1001/50000: loss: 0.9293643 - mea: 0.9614011\n","\t2001/50000: loss: 0.6107851 - mea: 0.7814663\n","\t3001/50000: loss: 0.6091944 - mea: 0.7804537\n","\t4001/50000: loss: 0.6065084 - mea: 0.7787365\n","\t5001/50000: loss: 0.6039546 - mea: 0.7770998\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<br/>Waiting for W&B process to finish, PID 1167<br/>Program failed with code 1.  Press ctrl-c to abort syncing."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0648eaa0037d47e2878f597d3e245277","version_minor":0,"version_major":2},"text/plain":["VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Control-C detected -- Run data was not synced\n"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-ff7b707001eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# Build, train and analyze the model with the pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-16-04d4f9116343>\u001b[0m in \u001b[0;36mmodel_pipeline\u001b[0;34m(hyperparameters)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             config.NUM_ITERS)\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mabs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-04d4f9116343>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_data, criterion, optimizer, num_iters)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0mmea\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2928\u001b[0m     \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2929\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"I6bBY8VzQ9ED"},"source":["### Wandb pipeline"]},{"cell_type":"code","metadata":{"id":"pSHPDLFSQ7RK","executionInfo":{"status":"ok","timestamp":1623402373154,"user_tz":-180,"elapsed":540,"user":{"displayName":"Дмитрий Галимзянов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZ2mpZj6x-74uzGNTk9Ws2YdRT3z-muP6KTkS4zg=s64","userId":"11134509458244039564"}}},"source":["\"\"\"\n","pipeline for training model and tracking weights, gradients and metrics via Wandb\n","\"\"\"\n","\n","def model_pipeline(hyperparameters):\n","    with wandb.init(project=f\"{hyperparameters['project']}\",\n","                    group=f\"{hyperparameters['function']}\", \n","                    job_type=f\"{hyperparameters['model']}\",\n","                    name=f\"{hyperparameters['function']}_{hyperparameters['model']}\",\n","                    tags=f\"{hyperparameters['tags']}\",\n","                    config=hyperparameters):\n","        config = wandb.config\n","\n","        random_model, model, data, criterion, optimizer = make(config)\n","        # print(model)\n","\n","        # data\n","        train_data, test_data = data\n"," \n","        # random_model\n","        random_mea = []\n","        for i in range(100):\n","            abs = test(random_model, test_data)\n","            random_mea.append(abs.mean().item())\n","        random_result = np.mean(random_mea)\n","\n","        # model\n","        train(model, \n","            train_data,\n","            criterion, \n","            optimizer,\n","            config.NUM_ITERS)\n","        \n","        abs = test(model, test_data)\n","        result = abs.mean().item()\n","        normalized_result = 100.0 * result/random_result\n","\n","        print('model_type:', config.model)\n","        print('function:', config.function)\n","        print('test_result:', result)\n","        print('normalized_test_result:', normalized_result)\n","\n","        ###wand plots\n","        # id = FUNC_id[config.function]\n","\n","        table_res = wandb.Table(data=[[config.function, result]], \n","                                columns=[\"FUNCTION\", \"Mean_of_MAE\"])\n","        \n","        table_norm_res = wandb.Table(data=[[config.function, normalized_result]], \n","                                     columns=[\"FUNCTION\", \"Scaled_Mean_of_MAE\"])\n","\n","        wandb.log({\n","        'Results': wandb.plot.bar(table_res, \n","                                \"FUNCTION\",\n","                                \"Mean_of_MAE\",\n","                                title=\"Results\"),\n","                   \n","        'Normalized_Results': wandb.plot.bar(table_norm_res, \n","                                            \"FUNCTION\",\n","                                            \"Scaled_Mean_of_MAE\", \n","                                            title=\"Normalized_Results\")\n","        })\n","\n","    return model\n","\n","\n","def make(config):\n","    # Make the model\n","    model = MODELS[config.model](config.NUM_LAYERS, \n","                                config.in_dim, \n","                                config.HIDDEN_DIM, \n","                                config.out_dim).model\n","\n","    random_model = MLP(config.NUM_LAYERS, \n","                        config.in_dim, \n","                        config.HIDDEN_DIM, \n","                        config.out_dim).model\n","\n","    # Make the data\n","    data = generate_data(config.function,\n","                         config.num_train, \n","                         config.num_test, \n","                         config.dim, \n","                         config.num_sum, \n","                         config.RANGE)\n","    \n","    # Make the loss and optimizer\n","    criterion = F.mse_loss\n","    optimizer = torch.optim.RMSprop(model.parameters(), lr=config.LEARNING_RATE)\n","\n","    # return random_model, model, criterion, optimizer\n","    return random_model, model, data, criterion, optimizer\n","\n","\n","def generate_data(function, num_train, num_test, dim, num_sum, support):\n","\n","    fn = ARITHMETIC_FUNCTIONS[function]\n","    data = torch.FloatTensor(dim).uniform_(*support).unsqueeze_(1)\n","    X, y = [], []\n","    for i in range(num_train + num_test):\n","        idx_a = random.sample(range(dim), num_sum)\n","        idx_b = random.sample([x for x in range(dim) if x not in idx_a], num_sum)\n","        a, b = data[idx_a].sum(), data[idx_b].sum()\n","        X.append([a, b])\n","        y.append(fn(a, b))\n","    X = torch.FloatTensor(X)\n","    y = torch.FloatTensor(y).unsqueeze_(1)\n","    indices = list(range(num_train + num_test))\n","    np.random.shuffle(indices)\n","    X_train, y_train = X[indices[num_test:]], y[indices[num_test:]]\n","    X_test, y_test = X[indices[:num_test]], y[indices[:num_test]]\n","\n","    return ((X_train, y_train), (X_test, y_test))\n","\n","\n","def train(model, train_data, criterion, optimizer, num_iters):\n","    wandb.watch(model, criterion, log=\"all\", log_freq=1000)\n","\n","    data, target = train_data\n","    # model.train()\n","    for i in range(num_iters):\n","        out = model(data)\n","        loss = criterion(out, target)\n","        mea = torch.mean(torch.abs(target - out))\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        if i % 1000 == 0:\n","            train_log(loss, mea, i, num_iters)\n","\n","def train_log(loss, mea, epoch, num_iters):\n","    wandb.log({\"epoch\": epoch, \"loss_(mse)\": loss.item(), 'mean_absolute_error': mea.item()})\n","    print(\"\\t{}/{}: loss: {:.7f} - mea: {:.7f}\".format(epoch+1, num_iters, loss.item(), mea.item()))\n","\n","\n","def test(model, test_data):\n","    data, target = test_data\n","    with torch.no_grad():\n","        out = model(data)\n","        return torch.abs(target - out)"],"execution_count":16,"outputs":[]}]}